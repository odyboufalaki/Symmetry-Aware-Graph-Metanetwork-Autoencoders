defaults:
  - model: pna
  - data: zoo_cifar_nfn_relu
  - _self_

n_epochs: 300
batch_size: 64

save_checkpoints: True

n_views: 1
num_workers: 8
# TODO: check the eval every, we currently use it to save every eval_every epochs
eval_every: 20
num_accum: 1
interpolation: False
interpolation_many_pairs: False
compile: false
compile_kwargs:
  # mode: reduce-overhead
  mode: null
  options:
    matmul-padding: True

optim:
  _target_: torch.optim.AdamW
  lr: 1e-4
  weight_decay: 5e-4
  amsgrad: True
  fused: False

loss:
  _target_: src.utils.loss.KnowledgeDistillationLoss
  temperature: 0.6

scheduler:
  _target_: src.neural_graphs.experiments.lr_scheduler.WarmupLRScheduler
  warmup_steps: 1000

distributed:
  world_size: 1
  rank: 0
  device_ids: null

load_ckpt: null

use_amp: False
gradscaler:
  enabled: ${use_amp}
autocast:
  device_type: cuda
  enabled: ${use_amp}
  dtype: float16

clip_grad: True
clip_grad_max_norm: 5.0

seed: 42
save_path: ./output
wandb:
  project: neural_graphs_cnn_relu
  entity: scale-gmns
  group: scale-gmns
  name: null
  tags: null

matmul_precision: high
cudnn_benchmark: False

debug: False
